{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup enviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from Paths import output_dir_absolute_path, root_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Deserialize(name):\n",
    "    with open(os.path.join(output_dir_absolute_path, name + \".json\"), 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetLabels(xlabel, ylabel,title):\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute EDA Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step may be skipped if the needed files are already in the *Outputs* folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import runpy\n",
    "\n",
    "scripts = glob.glob(os.path.join(root_dir, \"Source\", \"EDA scripts\", '*.py'))\n",
    "\n",
    "for script in scripts:\n",
    "    print(f'Executing: {script}')\n",
    "    runpy.run_path(script, run_name='__main__')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_counts = Deserialize('speakers_counts')\n",
    "plt.figure(figsize=(10, 5))\n",
    "n, bins, patches = plt.hist(speakers_counts.values(), edgecolor='black', bins=range(0,200,10))\n",
    "\n",
    "SetLabels(\"Number of recordings\",\"Number of speakers\",\"Number of recordings per participant\")\n",
    "plt.xticks(range(0,200,10))\n",
    "plt.yscale('log')\n",
    "plt.bar_label(patches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most participants recorded around 30-40 recordings, but there is also a large group of participants that recored more than 100 recordings and less than 30 recordings. This shows us that the data set is **unbalanced**, which may lead to **biased** predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_counts = Deserialize('labels_counts')\n",
    "bar = plt.barh(labels_counts.keys(), labels_counts.values(), edgecolor='black')\n",
    "\n",
    "SetLabels(\"Number of recordings\", \"Word\", \"Frequency of each word in recordings\")\n",
    "plt.xlim(0,50000)\n",
    "plt.bar_label(bar, padding=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of recordings per key word is **balanced**. However, there is a low number of recordings for \"silence\", which may lead to problems in detecting it. There is also a very high number of \"unknown\" recordings, which can result in tendency to mistakenly classify data in this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = Deserialize('lengths')\n",
    "n, bins, patches = plt.hist(lengths, edgecolor='black',bins=np.array(range(0,110,10))/100)\n",
    "\n",
    "SetLabels(\"Recording lengths in seconds\", \"Number of recordings\", \"Number of recordings per length\")\n",
    "plt.xticks(bins)\n",
    "plt.yscale(\"log\")\n",
    "plt.bar_label(patches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most recording have the same length of ~1 second. Some of them are shorter, which may be a result of bad processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length by Word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_word = Deserialize(\"lengths_by_word\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot(lengths_word.values(), tick_labels=lengths_word.keys(), orientation='horizontal')\n",
    "SetLabels(\"Duration [s]\", \"Word\", \"Distribution of duration per word\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "mean_lengths = {word: np.mean(times) if times else 0 for word, times in lengths_word.items()}\n",
    "plt.barh(mean_lengths.keys(), mean_lengths.values(), edgecolor=\"black\")\n",
    "plt.xscale(\"log\")\n",
    "SetLabels(\"Average Duration [s]\", \"Word\", \"Average Duration of words\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot shows that each class has many **outliers** - it may be mistakenly classified data or perhaps audio files cut too short. The second plot shows that there are significant differences between mean lengths of each word, which may be helpful in classifying them. We have to keep in mind that the mean duration may be heavily influenced by outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amplitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_amplitude = Deserialize(\"mean_amplitudes\")\n",
    "n, bins, patches = plt.hist(mean_amplitude, edgecolor='black', bins=range(0,18000,2000))\n",
    "\n",
    "SetLabels(\"Mean amplitude\", \"Number of recordings\", \"Mean amplitudes of recordings\")\n",
    "plt.xticks(bins)\n",
    "plt.yscale(\"log\")\n",
    "plt.bar_label(patches)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High number of recordings with mean amplitude smaller than 2000 shows us that most audio files have a similar volume level and it is not very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_amplitude = Deserialize(\"rms_amplitudes\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "n, bins, patches = plt.hist(rms_amplitude, edgecolor='black',bins=range(0,24000,2000))\n",
    "\n",
    "SetLabels(\"RMS amplitude\", \"Number of recordings\", \"RMS amplitudes of recordings\")\n",
    "plt.xticks(bins)\n",
    "plt.yscale(\"log\")\n",
    "plt.bar_label(patches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMS amplitude shows that most recordings have **lower** volume. This may suggest that there are many recordings with silent parts or just complete silence. Other audio files have the RMS amplitude reaching up to 22000, which may be caused by background noise. Such big differences in amplitudes might suggest that **normalizing** volume might be a good idea. \n",
    "\n",
    "RMS amplitude histogram and Mean amplitude histogram are quite similar, which implies **low Peak-to-RMS ratio** - this means that the audio in the recordings is more **uniform** and may contain **noise**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMS by Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_word = Deserialize(\"rms_by_word\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot(rms_word.values(), tick_labels=rms_word.keys(), orientation='horizontal')\n",
    "SetLabels(\"Amplitude\", \"Word\", \"Distribution of RMS Amplitude per word\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "mean_rms = {word: np.mean(times) if times else 0 for word, times in rms_word.items()}\n",
    "plt.barh(mean_rms.keys(), mean_rms.values(), edgecolor=\"black\")\n",
    "plt.xscale(\"log\")\n",
    "SetLabels(\"Average RMS Amplitude\", \"Word\", \"Average RMS Amplitude of words\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most words have a pretty similar boxplot chart. Many **outliers** may suggest mistakenly classified data. Average value shows that there may be a **difference** for RMS amplitude of each word, which may be helpful in classifying them, but we have to keep in mind that the outliers may heavily influence this chart."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
