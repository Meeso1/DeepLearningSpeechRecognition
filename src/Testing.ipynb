{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96061636",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mConstants\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLabels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mUnpacking\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mPrepareAudioFiles\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prepare_audio_files\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mGenerateSpectrograms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_all_spectrograms\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSpectrogramLoading\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mModels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mTrainingHistory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingHistory\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hmali\\Desktop\\Programy\\Studia\\DeepLearningSpeechRecognition\\src\\Preprocessing\\GenerateSpectrograms.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchaudio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mT\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mConstants\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mPaths\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_audio_dir, train_spectrograms_dir, test_spectrograms_dir, test_audio_dir\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mConstants\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLabels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m all_folders\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Constants.Paths import *\n",
    "from Constants.Labels import *\n",
    "from Unpacking.PrepareAudioFiles import prepare_audio_files\n",
    "from Preprocessing.GenerateSpectrograms import generate_all_spectrograms\n",
    "from SpectrogramLoading import *\n",
    "from Models.TrainingHistory import TrainingHistory\n",
    "from Models.CnnModel import CnnModel\n",
    "from Models.WandbDetails import WandbDetails\n",
    "from Models.InputPadding import pad_to_length\n",
    "from Models.HistoryPlots import plot_loss_history, plot_accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_audio_files()\n",
    "generate_all_spectrograms(backend=\"soundfile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e99b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, val_paths = get_divided_paths_with_labels()\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(train_paths)\n",
    "random.shuffle(val_paths)\n",
    "\n",
    "train = [load_spectrogram_for_path(path_with_label) for path_with_label in train_paths]\n",
    "validation = [load_spectrogram_for_path(path_with_label) for path_with_label in val_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f416762",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, label_indexes = spectrograms_to_x_y(train)\n",
    "X_validation, y_validation, _ = spectrograms_to_x_y(validation, label_indexes)\n",
    "\n",
    "max_length = max(x.shape[1] for x in [*X_validation, *X_train])\n",
    "X_validation = pad_to_length(X_validation, max_length)\n",
    "X_train = pad_to_length(X_train, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f823c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.TransformerModel import TransformerModel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5d30df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Transformer\n",
    "\n",
    "def train_and_evaluate_transformer(params):\n",
    "    model = TransformerModel(\n",
    "        classes=labels,\n",
    "        embedding_dimension=params.get(\"embedding_dimension\", 512),\n",
    "        num_attention_heads=params.get(\"num_attention_heads\", 8),\n",
    "        num_encoder_layers=params.get(\"num_encoder_layers\", 6),\n",
    "        num_decoder_layers=params.get(\"num_decoder_layers\", 6),\n",
    "        dim_feedforward=params.get(\"dim_feedforward\", 2048),\n",
    "        dropout=params.get(\"dropout\", 0.1),\n",
    "        learning_rate=params.get(\"learning_rate\", 1e-4),\n",
    "        lr_decay=params.get(\"lr_decay\", 0.0),\n",
    "        beta_1=params.get(\"beta_1\", 0.9),\n",
    "        beta_2=params.get(\"beta_2\", 0.98),\n",
    "        eps=params.get(\"eps\", 1e-9),\n",
    "        print_every=None,\n",
    "        validate_every=1,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    model.train((X_train, y_train), (X_validation, y_validation), epochs=5, batch_size=32)\n",
    "    \n",
    "    y_pred_classes = model.predict(X_validation)\n",
    "    \n",
    "    acc = accuracy_score(y_validation, y_pred_classes)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
    "        y_validation, y_pred_classes, average=None, labels=list(range(len(labels)))\n",
    "    )\n",
    "    cm = confusion_matrix(y_validation, y_pred_classes)\n",
    "    history = model.get_history()\n",
    "    \n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"history\": history\n",
    "    }\n",
    "\n",
    "def save_results_to_json(results, filename):\n",
    "    serializable_results = []\n",
    "    \n",
    "    for result in results:\n",
    "        serializable_result = {\n",
    "            \"params\": result[\"params\"],\n",
    "            \"accuracy\": result[\"accuracy\"],\n",
    "            \"precision\": result[\"precision\"].tolist(),\n",
    "            \"recall\": result[\"recall\"].tolist(),\n",
    "            \"f1_score\": result[\"f1_score\"].tolist(),\n",
    "            \"confusion_matrix\": result[\"confusion_matrix\"].tolist(),\n",
    "            \"history\": {\n",
    "                \"loss\": result[\"history\"].loss,\n",
    "                \"val_loss\": result[\"history\"].val_loss,\n",
    "                \"accuracy\": result[\"history\"].accuracy,\n",
    "                \"val_accuracy\": result[\"history\"].val_accuracy,\n",
    "            }\n",
    "        }\n",
    "        serializable_results.append(serializable_result)\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(serializable_results, f, indent=4)\n",
    "\n",
    "param_grid = [\n",
    "    {**base_params, \"embedding_dimension\": 256},\n",
    "    {**base_params, \"embedding_dimension\": 512},\n",
    "    {**base_params, \"embedding_dimension\": 1024},\n",
    "    \n",
    "    {**base_params, \"num_attention_heads\": 4},\n",
    "    {**base_params, \"num_attention_heads\": 8},\n",
    "    {**base_params, \"num_attention_heads\": 16},\n",
    "    \n",
    "    {**base_params, \"dropout\": 0.1},\n",
    "    {**base_params, \"dropout\": 0.2},\n",
    "    {**base_params, \"dropout\": 0.3},\n",
    "    \n",
    "    {**base_params, \"learning_rate\": 1e-3},\n",
    "    {**base_params, \"learning_rate\": 1e-4},\n",
    "    {**base_params, \"learning_rate\": 1e-5},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in param_grid:\n",
    "    result = train_and_evaluate_transformer(params)\n",
    "    results.append(result)\n",
    "\n",
    "save_results_to_json(results, \"transformer_experiments_results.json\")\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nModel {i+1}\")\n",
    "    print(f\"Params: {result['params']}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {result['precision']}\")\n",
    "    print(f\"Recall: {result['recall']}\")\n",
    "    print(f\"F1-Score: {result['f1_score']}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(result[\"confusion_matrix\"], annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title(f'Confusion Matrix for Model {i+1}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c29f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing CNN\n",
    "\n",
    "def train_and_evaluate_cnn(params):\n",
    "    model = CnnModel(\n",
    "        classes=labels,\n",
    "        learning_rate=params.get(\"learning_rate\", 1e-3),\n",
    "        lr_decay=params.get(\"lr_decay\", 1e-4),\n",
    "        beta_1=params.get(\"beta_1\", 0.9),\n",
    "        beta_2=params.get(\"beta_2\", 0.999),\n",
    "        eps=params.get(\"eps\", 1e-8),\n",
    "        classifier_dropout_1=params.get(\"classifier_dropout_1\", 0.3),\n",
    "        classifier_dropout_2=params.get(\"classifier_dropout_2\", 0.3),\n",
    "        classifier_dropout_3=params.get(\"classifier_dropout_3\", 0.1),\n",
    "        print_every=None,\n",
    "        validate_every=1,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    model.train((X_train, y_train), (X_validation, y_validation), epochs=5, batch_size=32)\n",
    "    \n",
    "    y_pred_classes = model.predict(X_validation)\n",
    "    \n",
    "    acc = accuracy_score(y_validation, y_pred_classes)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
    "        y_validation, y_pred_classes, average=None, labels=list(range(len(labels)))\n",
    "    )\n",
    "    cm = confusion_matrix(y_validation, y_pred_classes)\n",
    "    history = model.get_history()\n",
    "    \n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"history\": history\n",
    "    }\n",
    "\n",
    "def save_results_to_json(results, filename):\n",
    "    serializable_results = []\n",
    "    \n",
    "    for result in results:\n",
    "        serializable_result = {\n",
    "            \"params\": result[\"params\"],\n",
    "            \"accuracy\": result[\"accuracy\"],\n",
    "            \"precision\": result[\"precision\"].tolist(),\n",
    "            \"recall\": result[\"recall\"].tolist(),\n",
    "            \"f1_score\": result[\"f1_score\"].tolist(),\n",
    "            \"confusion_matrix\": result[\"confusion_matrix\"].tolist(),\n",
    "            \"history\": {\n",
    "                \"loss\": result[\"history\"].loss,\n",
    "                \"val_loss\": result[\"history\"].val_loss,\n",
    "                \"accuracy\": result[\"history\"].accuracy,\n",
    "                \"val_accuracy\": result[\"history\"].val_accuracy,\n",
    "            }\n",
    "        }\n",
    "        serializable_results.append(serializable_result)\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(serializable_results, f, indent=4)\n",
    "\n",
    "# Definicja siatki parametr√≥w\n",
    "param_grid = [\n",
    "    {**base_params, \"classifier_dropout_1\": 0.2, \"classifier_dropout_2\": 0.2, \"classifier_dropout_3\": 0.1},\n",
    "    {**base_params, \"classifier_dropout_1\": 0.3, \"classifier_dropout_2\": 0.3, \"classifier_dropout_3\": 0.1},\n",
    "    {**base_params, \"classifier_dropout_1\": 0.4, \"classifier_dropout_2\": 0.4, \"classifier_dropout_3\": 0.2},\n",
    "    \n",
    "    {**base_params, \"learning_rate\": 1e-3},\n",
    "    {**base_params, \"learning_rate\": 1e-4},\n",
    "    {**base_params, \"learning_rate\": 5e-5},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in param_grid:\n",
    "    result = train_and_evaluate_cnn(params)\n",
    "    results.append(result)\n",
    "\n",
    "save_results_to_json(results, \"cnn_experiments_results.json\")\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nModel {i+1}\")\n",
    "    print(f\"Params: {result['params']}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {result['precision']}\")\n",
    "    print(f\"Recall: {result['recall']}\")\n",
    "    print(f\"F1-Score: {result['f1_score']}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(result[\"confusion_matrix\"], annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title(f'Confusion Matrix for Model {i+1}')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLM_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
